{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8379036,"sourceType":"datasetVersion","datasetId":4982562}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset\nfrom torchvision import datasets, transforms\nimport torchvision.transforms.functional as TF\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data.dataset import Subset\nfrom torchvision.models import segmentation\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.model_selection import train_test_split\nfrom torchvision.models.segmentation import fcn_resnet50, FCN_ResNet50_Weights\n\nimport time\nfrom PIL import Image\nimport os\nfrom contextlib import redirect_stdout\nimport ssl\n\nssl._create_default_https_context = ssl._create_unverified_context","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images_dir = '/kaggle/input/final-version/Stage 2/Stage 2images'\nmasks_dir = '/kaggle/input/final-version/Stage 2/Stage 2/masks'\ndataset_dir = '/kaggle/input/final-version/Stage 2/Stage 2'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 16\nlr = 0.0002\nnum_epochs = 150\npatience = 20\n\nval_size = 0.1\ntest_size = 0.02\ntrain_size = 0.88","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SingleMaskDataset(Dataset):\n    def __init__(self, root, transform_images=None, transform_masks=None):\n        self.root = root\n        self.transform_images = transform_images\n        self.transform_masks = transform_masks\n        self.image_files, self.mask_files = self._load_files()\n\n    def _load_files(self):\n        image_files = []\n        mask_files = []\n\n        image_dir = os.path.join(self.root, 'images')\n        mask_dir = os.path.join(self.root, 'masks')\n\n        image_names = sorted(os.listdir(image_dir))\n\n        for image_name in image_names:\n            if image_name.endswith('.png') or image_name.endswith('.bmp'):\n                image_path = os.path.join(image_dir, image_name)\n                mask_path = os.path.join(mask_dir, image_name)\n                mask_files.append(mask_path)\n                image_files.append(image_path)\n\n        return image_files, mask_files\n\n    def __getitem__(self, index):\n        image_path = self.image_files[index]\n        mask_path = self.mask_files[index]\n        \n        image = Image.open(image_path).convert(\"RGB\")\n        mask = Image.open(mask_path).convert(\"L\")\n\n        if self.transform_images is not None:\n            image = self.transform_images(image)\n        if self.transform_masks is not None:\n            mask = self.transform_masks(mask)\n\n        return image, mask\n\n    def __len__(self):\n        return len(self.image_files)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ntransform_images = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n])\n\ntransform_masks = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n])\n\nif os.path.exists(images_dir + '.DS_Store'):\n        os.remove(images_dir + '.DS_Store')\n        \nif os.path.exists(masks_dir + '.DS_Store'):\n        os.remove(masks_dir + '.DS_Store')\n        \ndataset = SingleMaskDataset(root=dataset_dir, transform_images=transform_images, transform_masks=transform_masks)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_indices = list(range(len(dataset)))\n\ntrain_indices, remaining_indices = train_test_split(all_indices, test_size=(val_size + test_size), random_state=42)\ntest_size_adjusted = test_size / (val_size + test_size)\nval_indices, test_indices = train_test_split(remaining_indices, test_size=test_size_adjusted, random_state=42)\n\nprint(\"Length of train indices:\", len(train_indices))\nprint(\"Length of validation indices:\", len(val_indices))\nprint(\"Length of test indices:\", len(test_indices))\n\ntrain_dataset = Subset(dataset, train_indices)\nval_dataset = Subset(dataset, val_indices)\ntest_dataset = Subset(dataset, test_indices)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = segmentation.deeplabv3_resnet50(pretrained=True)\nmodel.classifier[-1] = nn.Conv2d(256, 1, kernel_size=1)\nmodel.to(device)\n\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.AdamW(model.parameters(), lr=lr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dice_loss_per_image(logits, targets, smooth=1e-6):\n    logits = torch.sigmoid(logits)\n    \n    logits = logits.view(-1)\n    targets = targets.view(-1)\n    \n    intersection = torch.sum(logits * targets)\n    union = torch.sum(logits) + torch.sum(targets)\n    \n    dice = (2. * intersection + smooth) / (union + smooth)\n    \n    return 1. - dice\n\ndef dice_loss(logits, targets):\n    loss = 0\n    for logit, target in zip(logits, targets):\n        loss += dice_loss_per_image(logit, target)\n    \n    return loss / len(logits)\n\ndef find_optimal_threshold(logits, masks):\n    return 0.8","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loss_list = []\ntrain_iou_list = []\ntrain_precision_list = []\ntrain_recall_list = []\ntrain_f1_score_list = []\n\nval_loss_list = []\nval_iou_list = []\nval_precision_list = []\nval_recall_list = []\nval_f1_score_list = []\n\nbest_val_loss = float('inf')\nbest_model_path = 'best_model.pth'\nepochs_no_improve = 0\nearly_stop = False\n\nfor epoch in range(num_epochs):\n    start_time = time.time()\n    running_loss = 0.0\n    intersection = 0.0\n    union = 0.0\n    true_positives = 0.0\n    false_positives = 0.0\n    false_negatives = 0.0\n    correct_pixels = 0.0\n    total_pixels = 0.0\n\n    model.train()\n    for images, masks in train_loader:\n        images = images.to(device)\n        masks = masks.to(device)\n\n        optimizer.zero_grad()\n\n        outputs = model(images)\n        logits = outputs[\"out\"]\n\n        loss = dice_loss(logits, masks)\n\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n        threshold = find_optimal_threshold(logits, masks)\n        preds = torch.sigmoid(logits) > threshold\n\n        intersection += torch.sum(torch.logical_and(preds, masks)).item()\n        union += torch.sum(torch.logical_or(preds, masks)).item()\n        true_positives += torch.sum(torch.logical_and(preds, masks)).item()\n        false_positives += torch.sum(torch.logical_and(preds == 1, masks == 0)).item()\n        false_negatives += torch.sum(torch.logical_and(preds == 0, masks == 1)).item()\n        \n        correct_pixels += torch.sum(preds == masks).item()\n        total_pixels += torch.numel(preds)\n\n    epoch_loss = running_loss / len(train_loader)\n    iou = intersection / (union + 1e-6)\n    precision = true_positives / (true_positives + false_positives + 1e-6)\n    recall = true_positives / (true_positives + false_negatives + 1e-6)\n    f1_score = 2 * (precision * recall) / (precision + recall + 1e-6)\n    \n    pixel_acc = correct_pixels / total_pixels\n\n    train_loss_list.append(epoch_loss)\n    train_iou_list.append(iou)\n    train_precision_list.append(precision)\n    train_recall_list.append(recall)\n    train_f1_score_list.append(f1_score)\n\n    model.eval()\n    with torch.no_grad():\n        intersection_val = 0.0\n        union_val = 0.0\n        true_positives_val = 0.0\n        false_positives_val = 0.0\n        false_negatives_val = 0.0\n        correct_pixels_val = 0.0\n        total_pixels_val = 0.0\n        total_val_samples = 0\n        total_val_loss = 0.0\n\n        for val_images, val_masks in val_loader:\n            val_images = val_images.to(device)\n            val_masks = val_masks.to(device)\n\n            val_outputs = model(val_images)\n            val_logits = val_outputs[\"out\"]\n\n            val_loss = dice_loss(val_logits, val_masks)\n            total_val_loss += val_loss.item() * val_images.size(0)\n            total_val_samples += val_images.size(0)\n\n            val_preds = torch.sigmoid(val_logits) > threshold\n\n            intersection_val += torch.sum(torch.logical_and(val_preds, val_masks)).item()\n            union_val += torch.sum(torch.logical_or(val_preds, val_masks)).item()\n            true_positives_val += torch.sum(torch.logical_and(val_preds, val_masks)).item()\n            false_positives_val += torch.sum(torch.logical_and(val_preds == 1, val_masks == 0)).item()\n            false_negatives_val += torch.sum(torch.logical_and(val_preds == 0, val_masks == 1)).item()\n            \n            correct_pixels_val += torch.sum(val_preds == val_masks).item()\n            total_pixels_val += torch.numel(val_preds)\n\n        val_loss = total_val_loss / (total_val_samples + 1e-6)\n        val_iou = intersection_val / (union_val + 1e-6)\n        val_precision = true_positives_val / (true_positives_val + false_positives_val + 1e-6)\n        val_recall = true_positives_val / (true_positives_val + false_negatives_val + 1e-6)\n        val_f1_score = 2 * (val_precision * val_recall) / (val_precision + val_recall + 1e-6)\n        \n        val_pixel_acc = correct_pixels_val / total_pixels_val\n\n        val_loss_list.append(val_loss)\n        val_iou_list.append(val_iou)\n        val_precision_list.append(val_precision)\n        val_recall_list.append(val_recall)\n        val_f1_score_list.append(val_f1_score)\n\n        flag = False\n        if val_loss < best_val_loss:\n            flag = True\n            best_val_loss = val_loss\n            torch.save(model.state_dict(), best_model_path)\n            epochs_no_improve = 0\n        else:\n            epochs_no_improve += 1\n            if epochs_no_improve >= patience:\n                early_stop = True\n\n        end_time = time.time()\n        epoch_time = end_time - start_time\n\n        if (flag):\n            print(f\"Epoch [{epoch+1}/{num_epochs}]: {epoch_time:.2f}s | Saved Model\\nTrain Loss: {epoch_loss:.4f}, Train IoU: {iou:.4f}, Train Pixel Acc: {pixel_acc:.4f}\\nValidation Loss: {val_loss:.4f}, Validation IoU: {val_iou:.4f}, Pixel Acc: {val_pixel_acc:.4f}\")\n        else:\n            print(f\"Epoch [{epoch+1}/{num_epochs}]: {epoch_time:.2f}s\\nTrain Loss: {epoch_loss:.4f}, Train IoU: {iou:.4f}, Train Pixel Acc: {pixel_acc:.4f}\\nValidation Loss: {val_loss:.4f}, Validation IoU: {val_iou:.4f}, Pixel Acc: {val_pixel_acc:.4f}\")\n        \n        print('===================================================================================================')\n        \n        if early_stop:\n            print('========================Early Stopped========================')\n            break","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 5))\nplt.plot(train_loss_list, label='Training Loss')\nplt.plot(val_loss_list, label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Stage 2: Training and Validation Loss')\nplt.legend()\nplt.show()\n\nplt.figure(figsize=(10, 5))\nplt.plot(train_iou_list, label='Training IoU')\nplt.plot(val_iou_list, label='Validation IoU')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.title('Stage 2: Training and Validation IoU')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loss_list = []\ntest_iou_list = []\ntest_pixel_acc_list = []\n\nmodel.eval()\n\nwith torch.no_grad():\n    intersection_test = 0.0\n    union_test = 0.0\n    correct_pixels_test = 0.0\n    total_pixels_test = 0.0\n    total_test_samples = 0\n    total_test_loss = 0.0\n\n    for test_images, test_masks in test_loader:\n        test_images = test_images.to(device)\n        test_masks = test_masks.to(device, dtype=torch.float)\n\n        test_outputs = model(test_images)\n        logits = test_outputs[\"out\"]\n        \n        test_loss = dice_loss(logits, test_masks)\n        total_test_loss += test_loss.item() * test_images.size(0)\n        total_test_samples += test_images.size(0)\n        \n        threshold = find_optimal_threshold(logits, test_masks)\n        preds = torch.sigmoid(logits) > threshold\n\n        intersection_test += torch.sum(torch.logical_and(preds, test_masks)).item()\n        union_test += torch.sum(torch.logical_or(preds, test_masks)).item()\n        \n        correct_pixels_test += torch.sum(preds == test_masks).item()\n        total_pixels_test += torch.numel(preds)\n\n        test_images_numpy = test_images.cpu().numpy()\n        true_masks_numpy = test_masks.cpu().numpy()\n        pred_masks_numpy = preds.cpu().numpy()\n\n        for i in range(test_images_numpy.shape[0]):\n            fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n            axes[0].imshow(test_images_numpy[i].transpose(1, 2, 0))\n            axes[0].set_title(\"Original Image\")\n            axes[0].axis(\"off\")\n\n            true_mask = true_masks_numpy[i][0]\n            axes[1].imshow(true_mask, cmap='gray')\n            axes[1].set_title(\"True Mask\")\n            axes[1].axis(\"off\")\n\n            pred_mask = pred_masks_numpy[i][0]\n            axes[2].imshow(pred_mask, cmap='gray')\n            axes[2].set_title(\"Predicted Mask\")\n            axes[2].axis(\"off\")\n\n            plt.show()\n\n    test_loss = total_test_loss / (total_test_samples + 1e-6)\n    test_iou = intersection_test / (union_test + 1e-6)\n    test_pixel_acc = correct_pixels_test / total_pixels_test\n\n    test_loss_list.append(test_loss)\n    test_iou_list.append(test_iou)\n    test_pixel_acc_list.append(test_pixel_acc)\n\n    print(f'Test Loss: {test_loss:.4f}, Test IoU: {test_iou:.4f}, Test Pixel Acc: {test_pixel_acc:.4f}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}