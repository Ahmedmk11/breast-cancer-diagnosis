{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8027380,"sourceType":"datasetVersion","datasetId":4731044},{"sourceId":8103675,"sourceType":"datasetVersion","datasetId":4785597}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset\nfrom torchvision import datasets, transforms\nimport torchvision.transforms.functional as TF\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data.dataset import Subset\nfrom torchvision.models import segmentation\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.model_selection import train_test_split\nfrom torchvision.models.segmentation import fcn_resnet50, FCN_ResNet50_Weights\n\nimport time\nfrom PIL import Image\nimport os\nfrom contextlib import redirect_stdout\nimport ssl\n\nssl._create_default_https_context = ssl._create_unverified_context","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-04-13T08:39:27.575302Z","iopub.execute_input":"2024-04-13T08:39:27.576318Z","iopub.status.idle":"2024-04-13T08:39:31.385648Z","shell.execute_reply.started":"2024-04-13T08:39:27.576274Z","shell.execute_reply":"2024-04-13T08:39:31.384621Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"images_dir = '/kaggle/input/version-2/Stage 2/Stage 2/images'\nmasks_dir = '/kaggle/input/version-2/Stage 2/Stage 2/masks'\ndataset_dir = '/kaggle/input/version-2/Stage 2/Stage 2'","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:39:31.387656Z","iopub.execute_input":"2024-04-13T08:39:31.388203Z","iopub.status.idle":"2024-04-13T08:39:31.393048Z","shell.execute_reply.started":"2024-04-13T08:39:31.388143Z","shell.execute_reply":"2024-04-13T08:39:31.392150Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"batch_size = 16\nlr = 0.0005\nnum_epochs = 100\n\nval_size = 0.1\ntest_size = 0.02\ntrain_size = 1 - (val_size + test_size)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:39:31.394372Z","iopub.execute_input":"2024-04-13T08:39:31.394774Z","iopub.status.idle":"2024-04-13T08:39:31.402278Z","shell.execute_reply.started":"2024-04-13T08:39:31.394743Z","shell.execute_reply":"2024-04-13T08:39:31.401388Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class SingleMaskDataset(Dataset):\n    def __init__(self, root, transform_images=None, transform_masks=None):\n        self.root = root\n        self.transform_images = transform_images\n        self.transform_masks = transform_masks\n        self.image_files, self.mask_files = self._load_files()\n\n    def _load_files(self):\n        image_files = []\n        mask_files = []\n\n        image_dir = os.path.join(self.root, 'images')\n        mask_dir = os.path.join(self.root, 'masks')\n\n        image_names = sorted(os.listdir(image_dir))\n\n        for image_name in image_names:\n            if image_name.endswith('.png') or image_name.endswith('.bmp'):\n                image_path = os.path.join(image_dir, image_name)\n                mask_path = os.path.join(mask_dir, image_name)\n                mask_files.append(mask_path)\n                image_files.append(image_path)\n\n        return image_files, mask_files\n\n    def __getitem__(self, index):\n        image_path = self.image_files[index]\n        mask_path = self.mask_files[index]\n        \n        image = Image.open(image_path).convert(\"RGB\")\n        mask = Image.open(mask_path).convert(\"L\")\n\n        if self.transform_images is not None:\n            image = self.transform_images(image)\n        if self.transform_masks is not None:\n            mask = self.transform_masks(mask)\n\n        return image, mask\n\n    def __len__(self):\n        return len(self.image_files)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:39:31.405018Z","iopub.execute_input":"2024-04-13T08:39:31.405395Z","iopub.status.idle":"2024-04-13T08:39:31.416327Z","shell.execute_reply.started":"2024-04-13T08:39:31.405363Z","shell.execute_reply":"2024-04-13T08:39:31.415480Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ntransform_images = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n])\n\ntransform_masks = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n])\n\nif os.path.exists(images_dir + '.DS_Store'):\n        os.remove(images_dir + '.DS_Store')\n        \nif os.path.exists(masks_dir + '.DS_Store'):\n        os.remove(masks_dir + '.DS_Store')\n        \ndataset = SingleMaskDataset(root=dataset_dir, transform_images=transform_images, transform_masks=transform_masks)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:39:31.417596Z","iopub.execute_input":"2024-04-13T08:39:31.418169Z","iopub.status.idle":"2024-04-13T08:39:31.470205Z","shell.execute_reply.started":"2024-04-13T08:39:31.418138Z","shell.execute_reply":"2024-04-13T08:39:31.469532Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"all_indices = list(range(len(dataset)))\n\ntrain_indices, remaining_indices = train_test_split(all_indices, test_size=(val_size + test_size), random_state=42)\ntest_size_adjusted = test_size / (val_size + test_size)\nval_indices, test_indices = train_test_split(remaining_indices, test_size=test_size_adjusted, random_state=42)\n\nprint(\"Length of train indices:\", len(train_indices))\nprint(\"Length of validation indices:\", len(val_indices))\nprint(\"Length of test indices:\", len(test_indices))\n\ntrain_dataset = Subset(dataset, train_indices)\nval_dataset = Subset(dataset, val_indices)\ntest_dataset = Subset(dataset, test_indices)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:39:31.471227Z","iopub.execute_input":"2024-04-13T08:39:31.471577Z","iopub.status.idle":"2024-04-13T08:39:31.482412Z","shell.execute_reply.started":"2024-04-13T08:39:31.471545Z","shell.execute_reply":"2024-04-13T08:39:31.481528Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Length of train indices: 3877\nLength of validation indices: 440\nLength of test indices: 89\n","output_type":"stream"}]},{"cell_type":"code","source":"model = segmentation.deeplabv3_resnet50(pretrained=True)\nmodel.classifier[-1] = nn.Conv2d(256, 1, kernel_size=1)\nmodel.to(device)\n\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.AdamW(model.parameters(), lr=lr)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:39:31.483698Z","iopub.execute_input":"2024-04-13T08:39:31.484402Z","iopub.status.idle":"2024-04-13T08:39:32.436604Z","shell.execute_reply.started":"2024-04-13T08:39:31.484359Z","shell.execute_reply":"2024-04-13T08:39:32.435830Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"}]},{"cell_type":"code","source":"def dice_loss_per_image(logits, targets, smooth=1e-6):\n    logits = torch.sigmoid(logits)\n    \n    logits = logits.view(-1)\n    targets = targets.view(-1)\n    \n    intersection = torch.sum(logits * targets)\n    union = torch.sum(logits) + torch.sum(targets)\n    \n    dice = (2. * intersection + smooth) / (union + smooth)\n    \n    return 1. - dice\n\ndef dice_loss(logits, targets):\n    loss = 0\n    for logit, target in zip(logits, targets):\n        loss += dice_loss_per_image(logit, target)\n    \n    return loss / len(logits)\n\ndef find_optimal_threshold(logits, masks):\n    return 0.8","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:39:32.437681Z","iopub.execute_input":"2024-04-13T08:39:32.437972Z","iopub.status.idle":"2024-04-13T08:39:32.444856Z","shell.execute_reply.started":"2024-04-13T08:39:32.437947Z","shell.execute_reply":"2024-04-13T08:39:32.444018Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_loss_list = []\ntrain_iou_list = []\ntrain_precision_list = []\ntrain_recall_list = []\ntrain_f1_score_list = []\n\nval_loss_list = []\nval_iou_list = []\nval_precision_list = []\nval_recall_list = []\nval_f1_score_list = []\n\nbest_val_loss = float('inf')\nbest_model_path = 'best_model.pth'\n\nfor epoch in range(num_epochs):\n    start_time = time.time()\n    running_loss = 0.0\n    intersection = 0.0\n    union = 0.0\n    true_positives = 0.0\n    false_positives = 0.0\n    false_negatives = 0.0\n\n    model.train()\n    for images, masks in train_loader:\n        images = images.to(device)\n        masks = masks.to(device)\n\n        optimizer.zero_grad()\n\n        outputs = model(images)\n        logits = outputs[\"out\"]\n\n        loss = dice_loss(logits, masks)\n\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n        threshold = find_optimal_threshold(logits, masks)\n        preds = torch.sigmoid(logits) > threshold\n\n        intersection += torch.sum(torch.logical_and(preds, masks)).item()\n        union += torch.sum(torch.logical_or(preds, masks)).item()\n        true_positives += torch.sum(torch.logical_and(preds, masks)).item()\n        false_positives += torch.sum(torch.logical_and(preds == 1, masks == 0)).item()\n        false_negatives += torch.sum(torch.logical_and(preds == 0, masks == 1)).item()\n\n    epoch_loss = running_loss / len(train_loader)\n    iou = intersection / (union + 1e-6)\n    precision = true_positives / (true_positives + false_positives + 1e-6)\n    recall = true_positives / (true_positives + false_negatives + 1e-6)\n    f1_score = 2 * (precision * recall) / (precision + recall + 1e-6)\n\n    train_loss_list.append(epoch_loss)\n    train_iou_list.append(iou)\n    train_precision_list.append(precision)\n    train_recall_list.append(recall)\n    train_f1_score_list.append(f1_score)\n\n    model.eval()\n    with torch.no_grad():\n        intersection_val = 0.0\n        union_val = 0.0\n        true_positives_val = 0.0\n        false_positives_val = 0.0\n        false_negatives_val = 0.0\n        total_val_samples = 0\n        total_val_loss = 0.0\n\n        for val_images, val_masks in val_loader:\n            val_images = val_images.to(device)\n            val_masks = val_masks.to(device)\n\n            val_outputs = model(val_images)\n            val_logits = val_outputs[\"out\"]\n\n            val_loss = dice_loss(val_logits, val_masks)\n            total_val_loss += val_loss.item() * val_images.size(0)\n            total_val_samples += val_images.size(0)\n\n            val_preds = torch.sigmoid(val_logits) > threshold\n\n            intersection_val += torch.sum(torch.logical_and(val_preds, val_masks)).item()\n            union_val += torch.sum(torch.logical_or(val_preds, val_masks)).item()\n            true_positives_val += torch.sum(torch.logical_and(val_preds, val_masks)).item()\n            false_positives_val += torch.sum(torch.logical_and(val_preds == 1, val_masks == 0)).item()\n            false_negatives_val += torch.sum(torch.logical_and(val_preds == 0, val_masks == 1)).item()\n\n        val_loss = total_val_loss / (total_val_samples + 1e-6)\n        val_iou = intersection_val / (union_val + 1e-6)\n        val_precision = true_positives_val / (true_positives_val + false_positives_val + 1e-6)\n        val_recall = true_positives_val / (true_positives_val + false_negatives_val + 1e-6)\n        val_f1_score = 2 * (val_precision * val_recall) / (val_precision + val_recall + 1e-6)\n\n        val_loss_list.append(val_loss)\n        val_iou_list.append(val_iou)\n        val_precision_list.append(val_precision)\n        val_recall_list.append(val_recall)\n        val_f1_score_list.append(val_f1_score)\n\n        flag = False\n        if val_loss < best_val_loss:\n            flag = True\n            best_val_loss = val_loss\n            torch.save(model.state_dict(), best_model_path)\n\n        end_time = time.time()\n        epoch_time = end_time - start_time\n\n        if (flag):\n            print(f\"Epoch [{epoch+1}/{num_epochs}]: {epoch_time:.2f}s | Saved Model\\nTrain Loss: {epoch_loss:.4f}, Train IoU: {iou:.4f}\\nValidation Loss: {val_loss:.4f}, IoU: {val_iou:.4f}\")\n        else:\n            print(f\"Epoch [{epoch+1}/{num_epochs}]: {epoch_time:.2f}s\\nTrain Loss: {epoch_loss:.4f}, Train IoU: {iou:.4f}\\nValidation Loss: {val_loss:.4f}, IoU: {val_iou:.4f}\")\n        \n        print('===================================================================================================')","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-04-13T08:39:32.446318Z","iopub.execute_input":"2024-04-13T08:39:32.446616Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch [1/100]: 176.71s | Saved Model\nTrain Loss: 0.3520, Train IoU: 0.5986\nValidation Loss: 0.2290, IoU: 0.6850\n===================================================================================================\nEpoch [2/100]: 177.25s | Saved Model\nTrain Loss: 0.1962, Train IoU: 0.7025\nValidation Loss: 0.1905, IoU: 0.7356\n===================================================================================================\nEpoch [3/100]: 177.39s | Saved Model\nTrain Loss: 0.1730, Train IoU: 0.7240\nValidation Loss: 0.1795, IoU: 0.7361\n===================================================================================================\nEpoch [4/100]: 177.88s | Saved Model\nTrain Loss: 0.1591, Train IoU: 0.7371\nValidation Loss: 0.1645, IoU: 0.7582\n===================================================================================================\nEpoch [5/100]: 176.81s\nTrain Loss: 0.1458, Train IoU: 0.7576\nValidation Loss: 0.1764, IoU: 0.7529\n===================================================================================================\nEpoch [6/100]: 177.45s | Saved Model\nTrain Loss: 0.1445, Train IoU: 0.7650\nValidation Loss: 0.1631, IoU: 0.7499\n===================================================================================================\nEpoch [7/100]: 176.94s\nTrain Loss: 0.1424, Train IoU: 0.7643\nValidation Loss: 0.1799, IoU: 0.7058\n===================================================================================================\nEpoch [8/100]: 180.28s\nTrain Loss: 0.1606, Train IoU: 0.7399\nValidation Loss: 0.1667, IoU: 0.7550\n===================================================================================================\nEpoch [9/100]: 176.93s | Saved Model\nTrain Loss: 0.1457, Train IoU: 0.7591\nValidation Loss: 0.1583, IoU: 0.7615\n===================================================================================================\nEpoch [10/100]: 177.80s | Saved Model\nTrain Loss: 0.1272, Train IoU: 0.7887\nValidation Loss: 0.1551, IoU: 0.7683\n===================================================================================================\nEpoch [11/100]: 177.33s | Saved Model\nTrain Loss: 0.1263, Train IoU: 0.7871\nValidation Loss: 0.1517, IoU: 0.7656\n===================================================================================================\nEpoch [12/100]: 176.73s\nTrain Loss: 0.1210, Train IoU: 0.7962\nValidation Loss: 0.1630, IoU: 0.7444\n===================================================================================================\nEpoch [13/100]: 177.11s\nTrain Loss: 0.1264, Train IoU: 0.7909\nValidation Loss: 0.1654, IoU: 0.7721\n===================================================================================================\nEpoch [14/100]: 177.17s | Saved Model\nTrain Loss: 0.1247, Train IoU: 0.7904\nValidation Loss: 0.1503, IoU: 0.7593\n===================================================================================================\nEpoch [15/100]: 176.86s\nTrain Loss: 0.1144, Train IoU: 0.8041\nValidation Loss: 0.1536, IoU: 0.7822\n===================================================================================================\nEpoch [16/100]: 176.37s\nTrain Loss: 0.1090, Train IoU: 0.8157\nValidation Loss: 0.1519, IoU: 0.7662\n===================================================================================================\nEpoch [17/100]: 176.69s\nTrain Loss: 0.1097, Train IoU: 0.8102\nValidation Loss: 0.1932, IoU: 0.6973\n===================================================================================================\nEpoch [18/100]: 176.58s\nTrain Loss: 0.1108, Train IoU: 0.8093\nValidation Loss: 0.1524, IoU: 0.7641\n===================================================================================================\nEpoch [19/100]: 177.83s | Saved Model\nTrain Loss: 0.1172, Train IoU: 0.8040\nValidation Loss: 0.1492, IoU: 0.7672\n===================================================================================================\nEpoch [20/100]: 182.00s\nTrain Loss: 0.1043, Train IoU: 0.8184\nValidation Loss: 0.1673, IoU: 0.7378\n===================================================================================================\nEpoch [21/100]: 198.64s | Saved Model\nTrain Loss: 0.1042, Train IoU: 0.8207\nValidation Loss: 0.1463, IoU: 0.7643\n===================================================================================================\nEpoch [22/100]: 178.19s | Saved Model\nTrain Loss: 0.0974, Train IoU: 0.8329\nValidation Loss: 0.1437, IoU: 0.7768\n===================================================================================================\nEpoch [23/100]: 176.81s\nTrain Loss: 0.0931, Train IoU: 0.8405\nValidation Loss: 0.1455, IoU: 0.7758\n===================================================================================================\nEpoch [24/100]: 176.59s\nTrain Loss: 0.1012, Train IoU: 0.8245\nValidation Loss: 0.1532, IoU: 0.7664\n===================================================================================================\nEpoch [25/100]: 176.61s\nTrain Loss: 0.1106, Train IoU: 0.8105\nValidation Loss: 0.1651, IoU: 0.7538\n===================================================================================================\nEpoch [26/100]: 178.68s | Saved Model\nTrain Loss: 0.0995, Train IoU: 0.8271\nValidation Loss: 0.1393, IoU: 0.7891\n===================================================================================================\nEpoch [27/100]: 176.50s\nTrain Loss: 0.0893, Train IoU: 0.8451\nValidation Loss: 0.1427, IoU: 0.7866\n===================================================================================================\nEpoch [28/100]: 176.83s\nTrain Loss: 0.0883, Train IoU: 0.8469\nValidation Loss: 0.1479, IoU: 0.7854\n===================================================================================================\nEpoch [29/100]: 176.90s\nTrain Loss: 0.0889, Train IoU: 0.8483\nValidation Loss: 0.1590, IoU: 0.7681\n===================================================================================================\nEpoch [30/100]: 176.83s\nTrain Loss: 0.1059, Train IoU: 0.8161\nValidation Loss: 0.1624, IoU: 0.7600\n===================================================================================================\nEpoch [31/100]: 176.66s\nTrain Loss: 0.0918, Train IoU: 0.8404\nValidation Loss: 0.1452, IoU: 0.7689\n===================================================================================================\nEpoch [32/100]: 177.54s\nTrain Loss: 0.0885, Train IoU: 0.8464\nValidation Loss: 0.1452, IoU: 0.7781\n===================================================================================================\nEpoch [33/100]: 176.46s\nTrain Loss: 0.0823, Train IoU: 0.8592\nValidation Loss: 0.1492, IoU: 0.7656\n===================================================================================================\nEpoch [34/100]: 176.57s\nTrain Loss: 0.0811, Train IoU: 0.8583\nValidation Loss: 0.1463, IoU: 0.7757\n===================================================================================================\n","output_type":"stream"}]},{"cell_type":"code","source":"epochs = range(1, num_epochs + 1)\n\nplt.figure(figsize=(12, 5))\n\nplt.subplot(2, 2, 1)\nplt.plot(epochs, train_loss_list, label='Train Loss')\nplt.plot(epochs, val_loss_list, label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training and Validation Loss')\nplt.legend()\n\nplt.subplot(2, 2, 2)\nplt.plot(epochs, train_iou_list, label='Train IoU')\nplt.plot(epochs, val_iou_list, label='Validation IoU')\nplt.xlabel('Epoch')\nplt.ylabel('IoU')\nplt.title('Training and Validation IoU')\nplt.legend()\n\nplt.subplot(2, 2, 3)\nplt.plot(epochs, train_precision_list, label='Train Precision')\nplt.plot(epochs, val_precision_list, label='Validation Precision')\nplt.xlabel('Epoch')\nplt.ylabel('Precision')\nplt.title('Training and Validation Precision')\nplt.legend()\n\nplt.subplot(2, 2, 4)\nplt.plot(epochs, train_recall_list, label='Train Recall')\nplt.plot(epochs, val_recall_list, label='Validation Recall')\nplt.xlabel('Epoch')\nplt.ylabel('Recall')\nplt.title('Training and Validation Recall')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loss_list = []\ntest_iou_list = []\n\nmodel.load_state_dict(torch.load('best_model.pth'))\nmodel.eval()\n\nwith torch.no_grad():\n    intersection_test = 0.0\n    union_test = 0.0\n    total_test_samples = 0\n    total_test_loss = 0.0\n\n    for test_images, test_masks in test_loader:\n        test_images = test_images.to(device)\n        test_masks = test_masks.to(device, dtype=torch.float)\n\n        test_outputs = model(test_images)\n        logits = test_outputs[\"out\"]\n        \n        test_loss = dice_loss(logits, test_masks)\n        total_test_loss += test_loss.item() * test_images.size(0)\n        total_test_samples += test_images.size(0)\n        \n        threshold = find_optimal_threshold(logits, test_masks)\n        preds = torch.sigmoid(logits) > threshold\n\n        intersection_test += torch.sum(torch.logical_and(preds, test_masks)).item()\n        union_test += torch.sum(torch.logical_or(preds, test_masks)).item()\n\n        test_images_numpy = test_images.cpu().numpy()\n        true_masks_numpy = test_masks.cpu().numpy()\n        pred_masks_numpy = preds.cpu().numpy()\n\n        for i in range(test_images_numpy.shape[0]):\n            fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n            axes[0].imshow(test_images_numpy[i].transpose(1, 2, 0))\n            axes[0].set_title(\"Original Image\")\n            axes[0].axis(\"off\")\n\n            true_mask = true_masks_numpy[i][0]\n            axes[1].imshow(true_mask, cmap='gray')\n            axes[1].set_title(\"True Mask\")\n            axes[1].axis(\"off\")\n\n            pred_mask = pred_masks_numpy[i][0]\n            axes[2].imshow(pred_mask, cmap='gray')\n            axes[2].set_title(\"Predicted Mask\")\n            axes[2].axis(\"off\")\n\n            plt.show()\n\n    test_loss = total_test_loss / (total_test_samples + 1e-6)\n    test_iou = intersection_test / (union_test + 1e-6)\n\n    test_loss_list.append(test_loss)\n    test_iou_list.append(test_iou)\n\n    print(f'Test Loss: {test_loss:.4f}, Test IoU: {test_iou:.4f}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}